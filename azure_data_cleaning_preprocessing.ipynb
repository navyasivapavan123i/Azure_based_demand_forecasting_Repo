{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a77ee0ee",
   "metadata": {},
   "source": [
    "# Azure Demand Forecasting — Data Cleaning & Preprocessing\n",
    "Infosys Springboard Internship Notebook\n",
    "\n",
    "This notebook performs:\n",
    "- Data loading\n",
    "- Data inspection\n",
    "- Missing value handling\n",
    "- Type conversion\n",
    "- Outlier checks\n",
    "- Feature engineering for time series\n",
    "- Encoding categorical variables\n",
    "- Train/Test split for forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea45204",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv('azure_demand_forecasting_dataset.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc5944d3",
   "metadata": {},
   "source": [
    "## Basic Info & Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b947c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape, df.columns, df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adaa3a3d",
   "metadata": {},
   "source": [
    "## Convert Timestamp to Datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b838da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d2e3eda",
   "metadata": {},
   "source": [
    "## Check Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8355b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9dbbff1",
   "metadata": {},
   "source": [
    "## Remove Duplicate Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62bfaa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b17061",
   "metadata": {},
   "source": [
    "## Sort by Time (Important for Forecasting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99752da",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values('timestamp')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c63e6a5a",
   "metadata": {},
   "source": [
    "## Handle Invalid Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be40f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure no negative demand or capacity\n",
    "df['usage_units'] = df['usage_units'].clip(lower=0)\n",
    "df['provisioned_capacity'] = df['provisioned_capacity'].clip(lower=0)\n",
    "df['cost_usd'] = df['cost_usd'].clip(lower=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2916311",
   "metadata": {},
   "source": [
    "## Outlier Detection (IQR Method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae4af03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outliers(col):\n",
    "    Q1 = df[col].quantile(0.25)\n",
    "    Q3 = df[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower = Q1 - 1.5 * IQR\n",
    "    upper = Q3 + 1.5 * IQR\n",
    "    return df[(df[col] >= lower) & (df[col] <= upper)]\n",
    "\n",
    "for c in ['usage_units','cost_usd']:\n",
    "    df = remove_outliers(c)\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb5b3b3",
   "metadata": {},
   "source": [
    "## Feature Engineering — Time Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8295ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['year'] = df['timestamp'].dt.year\n",
    "df['month'] = df['timestamp'].dt.month\n",
    "df['day'] = df['timestamp'].dt.day\n",
    "df['day_of_week'] = df['timestamp'].dt.dayofweek\n",
    "df['weekofyear'] = df['timestamp'].dt.isocalendar().week.astype(int)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bacc7212",
   "metadata": {},
   "source": [
    "## Seasonal Flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6de7a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['is_weekend'] = df['day_of_week'].isin([5,6]).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f334968",
   "metadata": {},
   "source": [
    "## Encode Categorical Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f111248",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df, columns=['region','service_type'], drop_first=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6944a8dc",
   "metadata": {},
   "source": [
    "## Normalize Numeric Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1783e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "num_cols = ['usage_units','provisioned_capacity','cost_usd','availability_pct']\n",
    "scaler = StandardScaler()\n",
    "df[num_cols] = scaler.fit_transform(df[num_cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa4581b4",
   "metadata": {},
   "source": [
    "## Train-Test Split (Time Series Safe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0aa4daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_date = df['timestamp'].quantile(0.8)\n",
    "\n",
    "train = df[df['timestamp'] <= split_date]\n",
    "test = df[df['timestamp'] > split_date]\n",
    "\n",
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a4f98f7",
   "metadata": {},
   "source": [
    "## Save Cleaned Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f13ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('azure_cleaned_preprocessed.csv', index=False)\n",
    "print('Saved cleaned dataset')"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
